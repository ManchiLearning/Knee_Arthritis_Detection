{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67045a28-27d3-4015-b5ae-e47d2540711c",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe17cf-358f-4ef1-9709-98299eea8fd4",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "El preprocesamiento de datos es una etapa crucial en el desarrollo de cualquier proyecto de aprendizaje automático. Este proceso asegura que los datos estén en un formato adecuado y optimizado para el entrenamiento del modelo. En este notebook, llevaremos a cabo varias transformaciones y mejoras en el conjunto de datos de imágenes de rayos X de rodillas para asegurar la mejor calidad posible para el análisis y entrenamiento de modelos.\n",
    "\n",
    "Las etapas de preprocesamiento incluyen:\n",
    "\n",
    "1. Eliminación de imágenes duplicadas\n",
    "2. Separación de imágenes con dos rodillas\n",
    "3. Aumento de datos\n",
    "4. Normalización de valores de píxeles\n",
    "5. Conversión a escala de grises\n",
    "6. Redimensionamiento uniforme\n",
    "\n",
    "Cada una de estas etapas se explicará y justificará en detalle en las secciones siguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c7e204-45d9-45d9-a452-568937f10167",
   "metadata": {},
   "source": [
    "### Eliminación de Imágenes Duplicadas\n",
    "\n",
    "La eliminación de imágenes duplicadas es una etapa importante para asegurar que no haya redundancia en el conjunto de datos. Los duplicados pueden sesgar el entrenamiento del modelo y reducir su capacidad de generalización. Utilizaremos técnicas de hashing para identificar y eliminar imágenes duplicada. \n",
    "\n",
    "Después de copiar las imágenes no duplicadas a la carpeta de salida, podemos verificar el nuevo conteo de imágenes por categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90961cb0-67dc-4f0d-ba15-7be067b222a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de imágenes por categoría antes de eliminar duplicados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "normal      514\n",
       "doubtful    477\n",
       "mild        232\n",
       "moderate    221\n",
       "severe      206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de imágenes por categoría después de eliminar duplicados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "normal      482\n",
       "doubtful    469\n",
       "mild        219\n",
       "moderate    203\n",
       "severe      206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes duplicadas por categoría:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "doubtful     8\n",
       "mild        13\n",
       "moderate    18\n",
       "normal      32\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "data_path = os.path.join(base_path, 'data', 'raw', 'images')\n",
    "output_path = os.path.join(base_path, 'data', 'interim', 'non_duplicates')\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def calculate_image_hash(image):\n",
    "    \"\"\"\n",
    "    Calcula el hash MD5 de una imagen para identificar duplicados.\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return hashlib.md5(image).hexdigest()\n",
    "\n",
    "def verify_and_copy_non_duplicates(data_path, output_path):\n",
    "    \"\"\"\n",
    "    Verifica la presencia de imágenes duplicadas y copia las no duplicadas a la carpeta de salida.\n",
    "    \"\"\"\n",
    "    image_hashes = {}\n",
    "    duplicate_images = []\n",
    "    \n",
    "    for category in ['normal', 'doubtful', 'mild', 'moderate', 'severe']:\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        output_category_path = os.path.join(output_path, category)\n",
    "        os.makedirs(output_category_path, exist_ok=True)\n",
    "        \n",
    "        if not os.path.exists(category_path):\n",
    "            raise FileNotFoundError(f'La ruta especificada no existe: {category_path}')\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            if filename.lower().endswith(('png', 'jpg', 'jpeg')):  # Verificar si el archivo es una imagen\n",
    "                image = cv2.imread(file_path)\n",
    "                image_hash = calculate_image_hash(image)\n",
    "                \n",
    "                if image_hash in image_hashes:\n",
    "                    duplicate_images.append((category, filename, image_hashes[image_hash]))\n",
    "                else:\n",
    "                    image_hashes[image_hash] = (category, filename)\n",
    "                    # Copiar imagen no duplicada a la carpeta de salida\n",
    "                    cv2.imwrite(os.path.join(output_category_path, filename), image)\n",
    "    \n",
    "    duplicate_images_df = pd.DataFrame(duplicate_images, columns=['category', 'filename', 'original'])\n",
    "    \n",
    "    return duplicate_images_df\n",
    "\n",
    "# Ejecutar la función\n",
    "duplicate_images_df = verify_and_copy_non_duplicates(data_path, output_path)\n",
    "\n",
    "### Verificación del Nuevo Conteo de Imágenes por Categoría\n",
    "\n",
    "def count_images_per_category(path):\n",
    "    \"\"\"\n",
    "    Cuenta la cantidad de imágenes por categoría en la ruta especificada.\n",
    "    \"\"\"\n",
    "    category_counts = {'normal': 0, 'doubtful': 0, 'mild': 0, 'moderate': 0, 'severe': 0}\n",
    "    for category in category_counts.keys():\n",
    "        category_path = os.path.join(path, category)\n",
    "        if os.path.exists(category_path):\n",
    "            category_counts[category] = len(os.listdir(category_path))\n",
    "    return category_counts\n",
    "\n",
    "# Contar imágenes por categoría antes de eliminar duplicados\n",
    "pre_duplicate_counts = count_images_per_category(data_path)\n",
    "print(\"Conteo de imágenes por categoría antes de eliminar duplicados:\")\n",
    "display(pd.DataFrame.from_dict(pre_duplicate_counts, orient='index', columns=['count']))\n",
    "\n",
    "# Contar imágenes por categoría después de eliminar duplicados\n",
    "post_duplicate_counts = count_images_per_category(output_path)\n",
    "print(\"Conteo de imágenes por categoría después de eliminar duplicados:\")\n",
    "display(pd.DataFrame.from_dict(post_duplicate_counts, orient='index', columns=['count']))\n",
    "\n",
    "# Contar duplicados por categoría\n",
    "duplicate_counts = duplicate_images_df['category'].value_counts().sort_index()\n",
    "\n",
    "# Mostrar número de duplicados y cuántas se eliminaron por categoría\n",
    "print(\"Número de imágenes duplicadas por categoría:\")\n",
    "display(duplicate_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b8ece-e30f-4def-ae9f-593e3c1caa8b",
   "metadata": {},
   "source": [
    "### Identificación y Separación de Imágenes con Dos Rodillas\n",
    "\n",
    "En esta sección, se separan las imágenes que contienen dos rodillas en dos imágenes individuales, una por cada rodilla. Este paso es crucial para estandarizar el dataset y asegurar que cada imagen contenga una única rodilla, facilitando así el procesamiento posterior y la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b38340-f721-402a-86ae-97f5e4e1b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de imágenes con una rodilla por categoría:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "normal      426\n",
       "doubtful    434\n",
       "mild        182\n",
       "moderate    165\n",
       "severe      206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de imágenes con dos rodillas por categoría:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "normal       56\n",
       "doubtful     35\n",
       "mild         37\n",
       "moderate     38\n",
       "severe        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'non_duplicates')\n",
    "output_path = os.path.join(base_path, 'data', 'interim', 'separated_knees')\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def get_prefix_and_suffix(category):\n",
    "    \"\"\"\n",
    "    Retorna el prefijo y el sufijo basado en la categoría.\n",
    "    \"\"\"\n",
    "    category_dict = {\n",
    "        'normal': 'NormalG0',\n",
    "        'doubtful': 'DoubtfulG1',\n",
    "        'mild': 'MildG2',\n",
    "        'moderate': 'ModerateG3',\n",
    "        'severe': 'SevereG4'\n",
    "    }\n",
    "    return category_dict.get(category, '')\n",
    "\n",
    "def count_and_separate_knees(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Identifica y separa las imágenes con dos rodillas.\n",
    "    \"\"\"\n",
    "    knee_count_data = {'normal': 0, 'doubtful': 0, 'mild': 0, 'moderate': 0, 'severe': 0}\n",
    "    two_knees_data = {'normal': 0, 'doubtful': 0, 'mild': 0, 'moderate': 0, 'severe': 0}\n",
    "    \n",
    "    for category in knee_count_data.keys():\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        output_category_path = os.path.join(output_path, category)\n",
    "        os.makedirs(output_category_path, exist_ok=True)\n",
    "        \n",
    "        prefix = get_prefix_and_suffix(category)\n",
    "        count = 1\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            image = cv2.imread(file_path)\n",
    "            height, width = image.shape[:2]\n",
    "            \n",
    "            if width == 640:  # Imágenes con dos rodillas\n",
    "                two_knees_data[category] += 1\n",
    "                \n",
    "                # Separar las dos rodillas\n",
    "                left_knee = image[:, :320]\n",
    "                right_knee = image[:, 320:]\n",
    "                \n",
    "                left_knee_filename = f\"{prefix} ({count})_left.png\"\n",
    "                right_knee_filename = f\"{prefix} ({count + 1})_right.png\"\n",
    "                \n",
    "                cv2.imwrite(os.path.join(output_category_path, left_knee_filename), left_knee)\n",
    "                cv2.imwrite(os.path.join(output_category_path, right_knee_filename), right_knee)\n",
    "                count += 2\n",
    "            else:\n",
    "                knee_count_data[category] += 1\n",
    "                new_filename = f\"{prefix} ({count}).png\"\n",
    "                cv2.imwrite(os.path.join(output_category_path, new_filename), image)\n",
    "                count += 1\n",
    "    \n",
    "    return knee_count_data, two_knees_data\n",
    "\n",
    "# Ejecutar la función y mostrar los resultados\n",
    "knee_count_data, two_knees_data = count_and_separate_knees(input_path, output_path)\n",
    "\n",
    "print(\"Conteo de imágenes con una rodilla por categoría:\")\n",
    "display(pd.DataFrame.from_dict(knee_count_data, orient='index', columns=['count']))\n",
    "\n",
    "print(\"Conteo de imágenes con dos rodillas por categoría:\")\n",
    "display(pd.DataFrame.from_dict(two_knees_data, orient='index', columns=['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f209fde-d9fc-480a-ae9d-668da8421289",
   "metadata": {},
   "source": [
    "### Aumento de Datos (Data Augmentation)\n",
    "\n",
    "El aumento de datos (Data Augmentation) se utilizará para generar más imágenes en las categorías menos representadas.\n",
    "\n",
    "Al hacer aumento de datos (data augmentation) en imágenes de radiografías de rodillas, es crucial preservar las características médicas importantes y evitar distorsiones que puedan afectar la interpretación médica. Aquí hay algunos criterios importantes a tener en cuenta:\n",
    "\n",
    "1. No Rotar las Imágenes: Mantener la orientación original de las rodillas.\n",
    "2. No Cambiar la Proporción de Aspecto: Preservar las proporciones originales para no distorsionar las características anatómicas.\n",
    "3. Ajuste de Brillo y Contraste: Permitir variaciones que podrían ocurrir debido a diferentes condiciones de escaneo.\n",
    "4. Añadir Ruido Gaussian: Imitar el ruido que podría estar presente en diferentes máquinas de escaneo.\n",
    "5. Ajuste de Escala Límite: Permitir un ligero cambio en la escala sin alterar las proporciones anatómicas.\n",
    "6. Desplazamiento Horizontal y Vertical: Permitir un ligero desplazamiento que podría ocurrir en diferentes condiciones de escaneo.\n",
    "7. Cortar y Pegar Pequeñas Porciones de la Imagen: Imitar posibles variaciones sin alterar la estructura general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928c4bed-c3f7-4d5a-aff2-46d6d2b083f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo inicial de imágenes por categoría:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "doubtful    504\n",
       "mild        256\n",
       "moderate    241\n",
       "normal      538\n",
       "severe      206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo después del aumento de datos por categoría:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "doubtful    504\n",
       "mild        500\n",
       "moderate    500\n",
       "normal      538\n",
       "severe      500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from IPython.display import display\n",
    "import torch\n",
    "\n",
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'separated_knees')\n",
    "output_path = os.path.join(base_path, 'data', 'interim', 'augmented')\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Definir el aumento de datos con Albumentations\n",
    "augmentation = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=0.2)\n",
    "    ], p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "def get_prefix_and_suffix(category):\n",
    "    \"\"\"\n",
    "    Retorna el prefijo y el sufijo basado en la categoría.\n",
    "    \"\"\"\n",
    "    category_dict = {\n",
    "        'normal': 'NormalG0',\n",
    "        'doubtful': 'DoubtfulG1',\n",
    "        'mild': 'MildG2',\n",
    "        'moderate': 'ModerateG3',\n",
    "        'severe': 'SevereG4'\n",
    "    }\n",
    "    return category_dict.get(category, '')\n",
    "\n",
    "def calculate_image_hash(image):\n",
    "    \"\"\"\n",
    "    Calcula el hash MD5 de una imagen para identificar duplicados.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(image).hexdigest()\n",
    "\n",
    "def augment_data(input_path, output_path, target_count=500):\n",
    "    \"\"\"\n",
    "    Realiza el aumento de datos para balancear las clases.\n",
    "    \"\"\"\n",
    "    category_counts = {category: len(os.listdir(os.path.join(input_path, category))) for category in os.listdir(input_path)}\n",
    "    image_hashes = set()\n",
    "    \n",
    "    for category in category_counts.keys():\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        output_category_path = os.path.join(output_path, category)\n",
    "        os.makedirs(output_category_path, exist_ok=True)\n",
    "        \n",
    "        images = []\n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            if filename.lower().endswith(('png', 'jpg', 'jpeg')):  # Verificar si el archivo es una imagen\n",
    "                image = cv2.imread(file_path)\n",
    "                image_hash = calculate_image_hash(image)\n",
    "                image_hashes.add(image_hash)\n",
    "                images.append((filename, image))\n",
    "                output_filepath = os.path.join(output_category_path, filename)\n",
    "                cv2.imwrite(output_filepath, image)  # Guardar la imagen original también\n",
    "        \n",
    "        prefix = get_prefix_and_suffix(category)\n",
    "        existing_count = category_counts[category]\n",
    "        \n",
    "        # Generar imágenes aumentadas\n",
    "        if len(images) > 0:\n",
    "            while category_counts[category] < target_count:\n",
    "                for i, (filename, image) in enumerate(images):\n",
    "                    augmented = augmentation(image=image)[\"image\"]\n",
    "                    aug_image_hash = calculate_image_hash(augmented.numpy().transpose(1, 2, 0))\n",
    "                    if aug_image_hash not in image_hashes:\n",
    "                        aug_filename = f\"{prefix} ({existing_count + 1})_augmented.png\"\n",
    "                        aug_filepath = os.path.join(output_category_path, aug_filename)\n",
    "                        cv2.imwrite(aug_filepath, augmented.numpy().transpose(1, 2, 0))  # Convertir tensor a imagen\n",
    "                        category_counts[category] += 1\n",
    "                        existing_count += 1\n",
    "                        image_hashes.add(aug_image_hash)\n",
    "                    if category_counts[category] >= target_count:\n",
    "                        break\n",
    "    \n",
    "    return category_counts\n",
    "\n",
    "# Ejecutar la función y mostrar los resultados\n",
    "initial_counts = {category: len(os.listdir(os.path.join(input_path, category))) for category in os.listdir(input_path)}\n",
    "augmented_counts = augment_data(input_path, output_path)\n",
    "\n",
    "# Mostrar el conteo inicial de imágenes por categoría\n",
    "print(\"Conteo inicial de imágenes por categoría:\")\n",
    "display(pd.DataFrame.from_dict(initial_counts, orient='index', columns=['count']))\n",
    "\n",
    "# Mostrar el conteo de imágenes después del aumento de datos por categoría\n",
    "print(\"Conteo después del aumento de datos por categoría:\")\n",
    "display(pd.DataFrame.from_dict(augmented_counts, orient='index', columns=['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687f6c1-3b4a-4996-9b36-9f35bf10913e",
   "metadata": {},
   "source": [
    "### Normalización de Imágenes\n",
    "\n",
    "La normalización es un paso crucial en el preprocesamiento de datos que consiste en escalar los valores de los píxeles de las imágenes a un rango estándar, como 0-1 o -1 a 1. Esto ayuda a mejorar la convergencia y el rendimiento de los algoritmos de machine learning y deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f34d762-a7ca-4b94-bda1-b972db4d6ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes normalizadas y guardadas en la carpeta 'normalized'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'augmented')\n",
    "output_path = os.path.join(base_path, 'data', 'interim', 'normalized')\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normaliza la imagen a valores entre 0 y 1.\n",
    "    \"\"\"\n",
    "    return image / 255.0\n",
    "\n",
    "def normalize_images(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Normaliza las imágenes y las guarda en la carpeta de salida.\n",
    "    \"\"\"\n",
    "    for category in os.listdir(input_path):\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        output_category_path = os.path.join(output_path, category)\n",
    "        os.makedirs(output_category_path, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            normalized_image = normalize_image(image)\n",
    "            output_file_path = os.path.join(output_category_path, filename)\n",
    "            cv2.imwrite(output_file_path, (normalized_image * 255).astype(np.uint8))\n",
    "\n",
    "# Ejecutar la función de normalización\n",
    "normalize_images(input_path, output_path)\n",
    "print(\"Imágenes normalizadas y guardadas en la carpeta 'normalized'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04904401-0f14-4771-a557-9c937f27d8ec",
   "metadata": {},
   "source": [
    "#### Revisión de Dimensionalidad de las Imágenes\n",
    "\n",
    "Verificar el número de canales que presenta cada una de las imágenes. En la etapa de verificación de la calidad de los datos, se identificó que las imágenes estaban a color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a655358a-818d-4fa8-a2c7-e93f13d26e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de imágenes por tipo de color:\n",
      "Color Type\n",
      "Color    2542\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Detalle de imágenes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Color Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (1).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (10).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (100).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (101).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (102).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>severe</td>\n",
       "      <td>SevereG4 (95).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>severe</td>\n",
       "      <td>SevereG4 (96).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>severe</td>\n",
       "      <td>SevereG4 (97).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>severe</td>\n",
       "      <td>SevereG4 (98).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>severe</td>\n",
       "      <td>SevereG4 (99).png</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2542 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category              Filename Color Type\n",
       "0     doubtful    DoubtfulG1 (1).png      Color\n",
       "1     doubtful   DoubtfulG1 (10).png      Color\n",
       "2     doubtful  DoubtfulG1 (100).png      Color\n",
       "3     doubtful  DoubtfulG1 (101).png      Color\n",
       "4     doubtful  DoubtfulG1 (102).png      Color\n",
       "...        ...                   ...        ...\n",
       "2537    severe     SevereG4 (95).png      Color\n",
       "2538    severe     SevereG4 (96).png      Color\n",
       "2539    severe     SevereG4 (97).png      Color\n",
       "2540    severe     SevereG4 (98).png      Color\n",
       "2541    severe     SevereG4 (99).png      Color\n",
       "\n",
       "[2542 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'normalized')\n",
    "\n",
    "def check_image_channels(input_path):\n",
    "    \"\"\"\n",
    "    Verifica el número de canales en cada imagen y clasifica si es blanco y negro o color.\n",
    "    \"\"\"\n",
    "    image_data = []\n",
    "    \n",
    "    for category in os.listdir(input_path):\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for filename in os.listdir(category_path):\n",
    "                if filename.lower().endswith(('png', 'jpg', 'jpeg')):  # Verificar si el archivo es una imagen\n",
    "                    file_path = os.path.join(category_path, filename)\n",
    "                    image = cv2.imread(file_path)\n",
    "                    if image is not None:\n",
    "                        channels = image.shape[2] if len(image.shape) == 3 else 1\n",
    "                        color_type = 'Color' if channels == 3 else 'Blanco y Negro'\n",
    "                        image_data.append((category, filename, color_type))\n",
    "    \n",
    "    return pd.DataFrame(image_data, columns=['Category', 'Filename', 'Color Type'])\n",
    "\n",
    "# Ejecutar la función\n",
    "image_color_df = check_image_channels(input_path)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Resumen de imágenes por tipo de color:\")\n",
    "print(image_color_df['Color Type'].value_counts())\n",
    "\n",
    "print(\"\\nDetalle de imágenes:\")\n",
    "display(image_color_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f311848-9973-4b2e-8c1c-dd830bca22c9",
   "metadata": {},
   "source": [
    "## Conversión a Escala de Grises\n",
    "\n",
    "La conversión a escala de grises es un paso esencial en el preprocesamiento de imágenes médicas, ya que reduce la complejidad de los datos sin perder información relevante para el análisis. Convertir las imágenes a escala de grises para simplificar el procesamiento y mejorar la eficiencia computacional.\n",
    "\n",
    "Las imágenes en escala de grises tienen menos dimensiones que las imágenes en color (1 canal en lugar de 3), lo que reduce el tiempo de procesamiento y la memoria requerida, sin comprometer la calidad de la información para las tareas de diagnóstico y análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21952fe-9715-4d4d-8890-c4c4bf3dba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes convertidas a escala de grises y guardadas en la carpeta 'grayscale'.\n"
     ]
    }
   ],
   "source": [
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'normalized')\n",
    "output_path = os.path.join(base_path, 'data', 'interim', 'grayscale')\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def convert_to_grayscale(image):\n",
    "    \"\"\"\n",
    "    Convierte una imagen a escala de grises.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def grayscale_images(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convierte las imágenes a escala de grises y las guarda en la carpeta de salida.\n",
    "    \"\"\"\n",
    "    for category in os.listdir(input_path):\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        output_category_path = os.path.join(output_path, category)\n",
    "        os.makedirs(output_category_path, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            image = cv2.imread(file_path)\n",
    "            grayscale_image = convert_to_grayscale(image)\n",
    "            output_file_path = os.path.join(output_category_path, filename)\n",
    "            cv2.imwrite(output_file_path, grayscale_image)\n",
    "\n",
    "# Ejecutar la función de conversión a escala de grises\n",
    "grayscale_images(input_path, output_path)\n",
    "print(\"Imágenes convertidas a escala de grises y guardadas en la carpeta 'grayscale'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a44865-bccb-4a98-bb83-faba0fb996d7",
   "metadata": {},
   "source": [
    "## Redimensionamiento Uniforme\n",
    "\n",
    "El redimensionamiento uniforme asegura que todas las imágenes tengan el mismo tamaño, lo cual es crucial para el entrenamiento de modelos de aprendizaje automático. Redimensionar todas las imágenes a un tamaño uniforme para garantizar la compatibilidad y eficiencia en el procesamiento posterior.\n",
    "\n",
    "Los modelos de aprendizaje automático requieren que las imágenes de entrada tengan dimensiones uniformes para poder procesarlas en lotes (batch processing). Además, un tamaño uniforme mejora la consistencia y el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c68da7a-dc9e-424c-ac98-9461ca84e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes redimensionadas y guardadas en la carpeta 'interim/resized'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "\n",
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'grayscale')\n",
    "interim_output_path = os.path.join(base_path, 'data', 'interim', 'resized')\n",
    "final_output_path = os.path.join(base_path, 'data', 'processed', 'images')\n",
    "\n",
    "# Crear las carpetas de salida si no existen\n",
    "os.makedirs(interim_output_path, exist_ok=True)\n",
    "os.makedirs(final_output_path, exist_ok=True)\n",
    "\n",
    "def resize_image(image, size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Redimensiona una imagen al tamaño especificado.\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "def resize_images(input_path, interim_output_path):\n",
    "    \"\"\"\n",
    "    Redimensiona las imágenes y las guarda en las carpetas de salida.\n",
    "    \"\"\"\n",
    "    for category in os.listdir(input_path):\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        interim_output_category_path = os.path.join(interim_output_path, category)\n",
    "        os.makedirs(interim_output_category_path, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            if filename.lower().endswith(('png', 'jpg', 'jpeg')):  # Verificar si el archivo es una imagen\n",
    "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                resized_image = resize_image(image)\n",
    "                interim_output_file_path = os.path.join(interim_output_category_path, filename)\n",
    "                cv2.imwrite(interim_output_file_path, resized_image)\n",
    "\n",
    "# Ejecutar la función de redimensionamiento\n",
    "resize_images(input_path, interim_output_path)\n",
    "print(\"Imágenes redimensionadas y guardadas en la carpeta 'interim/resized'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d891a8-e90b-4852-85c7-859ad11ed7db",
   "metadata": {},
   "source": [
    "### Revisión Final y Almacenamiento\n",
    "\n",
    "En esta sección, se realizará una revisión final de las imágenes preprocesadas y se almacenarán en la carpeta final para su uso en el entrenamiento de modelos. Asegurar que todas las imágenes preprocesadas estén en la forma y calidad deseada y almacenarlas en la carpeta final de datos procesados.\n",
    "\n",
    "Una revisión final asegura que todas las imágenes están correctamente preprocesadas y listas para su uso en los modelos de machine learning, garantizando la consistencia y calidad del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867c12fc-44bd-47b6-b46b-0bf9e405d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes revisadas y almacenadas en la carpeta 'processed/images'.\n",
      "Conteo final de imágenes por categoría:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubtful</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "normal      538\n",
       "doubtful    504\n",
       "mild        500\n",
       "moderate    500\n",
       "severe      500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir las rutas correctamente basadas en la ubicación del notebook\n",
    "base_path = os.path.abspath('')\n",
    "input_path = os.path.join(base_path, 'data', 'interim', 'resized')\n",
    "final_output_path = os.path.join(base_path, 'data', 'processed', 'images')\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "os.makedirs(final_output_path, exist_ok=True)\n",
    "\n",
    "def final_review_and_store_images(input_path, final_output_path):\n",
    "    \"\"\"\n",
    "    Realiza una revisión final de las imágenes y las almacena en la carpeta final.\n",
    "    \"\"\"\n",
    "    for category in os.listdir(input_path):\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        final_output_category_path = os.path.join(final_output_path, category)\n",
    "        os.makedirs(final_output_category_path, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, filename)\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # Realizar cualquier revisión final necesaria (por ejemplo, verificación de dimensiones)\n",
    "            if image.shape == (256, 256):\n",
    "                output_file_path = os.path.join(final_output_category_path, filename)\n",
    "                cv2.imwrite(output_file_path, image)\n",
    "\n",
    "# Ejecutar la función de revisión final y almacenamiento\n",
    "final_review_and_store_images(input_path, final_output_path)\n",
    "print(\"Imágenes revisadas y almacenadas en la carpeta 'processed/images'.\")\n",
    "\n",
    "def count_images_per_category(path):\n",
    "    \"\"\"\n",
    "    Cuenta la cantidad de imágenes por categoría en la ruta especificada.\n",
    "    \"\"\"\n",
    "    category_counts = {'normal': 0, 'doubtful': 0, 'mild': 0, 'moderate': 0, 'severe': 0}\n",
    "    for category in category_counts.keys():\n",
    "        category_path = os.path.join(path, category)\n",
    "        if os.path.exists(category_path):\n",
    "            category_counts[category] = len(os.listdir(category_path))\n",
    "    return category_counts\n",
    "\n",
    "# Contar imágenes por categoría después de la revisión final\n",
    "final_counts = count_images_per_category(final_output_path)\n",
    "print(\"Conteo final de imágenes por categoría:\")\n",
    "display(pd.DataFrame.from_dict(final_counts, orient='index', columns=['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195d112-ce59-4264-8f03-1f30812c27c9",
   "metadata": {},
   "source": [
    "### Revisión Adicional de Duplicados\n",
    "\n",
    "Verificación final de duplicados en cada una de las etapas del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b43952-21be-422d-b7de-193c6772bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\raw\\images:\n",
      "Se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\raw\\images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (332).png</td>\n",
       "      <td>(doubtful, DoubtfulG1 (329).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (386).png</td>\n",
       "      <td>(doubtful, DoubtfulG1 (383).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (453).png</td>\n",
       "      <td>(doubtful, DoubtfulG1 (447).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (466).png</td>\n",
       "      <td>(doubtful, DoubtfulG1 (450).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>DoubtfulG1 (76).png</td>\n",
       "      <td>(doubtful, DoubtfulG1 (73).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>normal</td>\n",
       "      <td>NormalG0 (474).png</td>\n",
       "      <td>(normal, NormalG0 (466).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>normal</td>\n",
       "      <td>NormalG0 (475).png</td>\n",
       "      <td>(normal, NormalG0 (457).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>normal</td>\n",
       "      <td>NormalG0 (476).png</td>\n",
       "      <td>(normal, NormalG0 (462).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>normal</td>\n",
       "      <td>NormalG0 (477).png</td>\n",
       "      <td>(normal, NormalG0 (464).png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>normal</td>\n",
       "      <td>NormalG0 (478).png</td>\n",
       "      <td>(normal, NormalG0 (460).png)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    category              filename                          original\n",
       "0   doubtful  DoubtfulG1 (332).png  (doubtful, DoubtfulG1 (329).png)\n",
       "1   doubtful  DoubtfulG1 (386).png  (doubtful, DoubtfulG1 (383).png)\n",
       "2   doubtful  DoubtfulG1 (453).png  (doubtful, DoubtfulG1 (447).png)\n",
       "3   doubtful  DoubtfulG1 (466).png  (doubtful, DoubtfulG1 (450).png)\n",
       "4   doubtful   DoubtfulG1 (76).png   (doubtful, DoubtfulG1 (73).png)\n",
       "..       ...                   ...                               ...\n",
       "66    normal    NormalG0 (474).png      (normal, NormalG0 (466).png)\n",
       "67    normal    NormalG0 (475).png      (normal, NormalG0 (457).png)\n",
       "68    normal    NormalG0 (476).png      (normal, NormalG0 (462).png)\n",
       "69    normal    NormalG0 (477).png      (normal, NormalG0 (464).png)\n",
       "70    normal    NormalG0 (478).png      (normal, NormalG0 (460).png)\n",
       "\n",
       "[71 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\non_duplicates:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\non_duplicates\n",
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\separated_knees:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\separated_knees\n",
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\augmented:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\augmented\n",
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\normalized:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\normalized\n",
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\grayscale:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\grayscale\n",
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\resized:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\interim\\resized\n",
      "Verificando duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\processed\\images:\n",
      "No se encontraron duplicados en C:\\Users\\gluna\\Desktop\\SIC\\SIC_2023_Capstone\\Github_Repo\\Knee_Arthritis_Detection\\data\\processed\\images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_image_hash(image):\n",
    "    \"\"\"\n",
    "    Calcula el hash MD5 de una imagen para identificar duplicados.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(image).hexdigest()\n",
    "\n",
    "def verify_duplicates(data_path):\n",
    "    \"\"\"\n",
    "    Verifica la presencia de imágenes duplicadas en la carpeta especificada.\n",
    "    \"\"\"\n",
    "    image_hashes = {}\n",
    "    duplicate_images = []\n",
    "    \n",
    "    for category in os.listdir(data_path):\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        if os.path.isdir(category_path):  # Verificar si es un directorio\n",
    "            for filename in os.listdir(category_path):\n",
    "                file_path = os.path.join(category_path, filename)\n",
    "                if filename.lower().endswith(('png', 'jpg', 'jpeg')):  # Verificar si el archivo es una imagen\n",
    "                    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    image_hash = calculate_image_hash(image)\n",
    "                    \n",
    "                    if image_hash in image_hashes:\n",
    "                        duplicate_images.append((category, filename, image_hashes[image_hash]))\n",
    "                    else:\n",
    "                        image_hashes[image_hash] = (category, filename)\n",
    "    \n",
    "    duplicate_images_df = pd.DataFrame(duplicate_images, columns=['category', 'filename', 'original'])\n",
    "    return duplicate_images_df\n",
    "\n",
    "# Verificación de duplicados para cada etapa\n",
    "data_paths = [\n",
    "    os.path.join(base_path, 'data', 'raw', 'images'),\n",
    "    os.path.join(base_path, 'data', 'interim', 'non_duplicates'),\n",
    "    os.path.join(base_path, 'data', 'interim', 'separated_knees'),\n",
    "    os.path.join(base_path, 'data', 'interim', 'augmented'),\n",
    "    os.path.join(base_path, 'data', 'interim', 'normalized'),\n",
    "    os.path.join(base_path, 'data', 'interim', 'grayscale'),\n",
    "    os.path.join(base_path, 'data', 'interim', 'resized'),\n",
    "    os.path.join(base_path, 'data', 'processed', 'images')\n",
    "]\n",
    "\n",
    "for path in data_paths:\n",
    "    print(f\"Verificando duplicados en {path}:\")\n",
    "    duplicate_images_df = verify_duplicates(path)\n",
    "    if not duplicate_images_df.empty:\n",
    "        print(f\"Se encontraron duplicados en {path}\")\n",
    "        display(duplicate_images_df)\n",
    "    else:\n",
    "        print(f\"No se encontraron duplicados en {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
